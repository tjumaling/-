————————————————————————————————————————————————————————————————————————————————————————————————————
【L1和L2的区别】
	L1范数: 为x向量各个元素绝对值之和。 
	L2范数: 为x向量各个元素平方和的1/2次方，L2范数又称Euclidean范数或者Frobenius范数 
	Lp范数: 为x向量各个元素绝对值p次方和的1/p次方。
	
	L1范数可以使权值稀疏，方便特征提取。 
	L2范数可以防止过拟合，提升模型的泛化能力。
	
	在靠进零附近, L1以匀速下降到零, 而L2则完全停下来了。
	L1是将不重要的特征尽快剔除, L2则是把特征贡献尽量压缩最小但不至于为零。
	两者一起作用, 就是把重要性在一个数量级的那些特征一起平等共事。
	
	L1和L2正则先验分别服从什么分布，L1是拉普拉斯分布，L2是高斯分布。
	Lasso回归（L1）同时做变量选择和参数收缩，而ridge回归只做参数收缩，并最终在模型中包含所有的系数。
	在对少量变量有中等或大尺度的影响的时候用lasso回归。在对多个变量只有小或中等尺度影响的时候，使用Ridge回归。
	
	为什么L1容易产生稀疏数据？正则函数的等高线和原始损失函数的等高线总是相交在坐标轴上。
	若参数很大，那么只要数据偏移一点点，就会对结果造成很大的影响
	但如果参数足够小，数据偏移得多一点也不会对结果造成什么影响，专业一点的说法是『抗扰动能力强』。


————————————————————————————————————————————————————————————————————————————————————————————————————
【过拟合的原因，以及如何防止过拟合】
	过拟合是在训练集上的误差很小，而在测试集上的误差大，泛化能力差。
	1）选择特征
	2）正则化
	3）交叉叉验证提前终止
	4）加入随机性：随机森林随机选择特征；神经元以超参数p的概率被激活，Dropout（随机删除神经元）
	5）增大训练量：数据源头，重采样，根据分布产生数据，复制数据加入噪声（图像旋转，裁剪，模糊，调亮度，平移，镜像）
	6）集成学习方法bagging(如随机森林）能有效防止过拟合
	
	
————————————————————————————————————————————————————————————————————————————————————————————————————
【欠拟合】
	训练误差和验证误差都很大。
	解决办法
	1）做特征工程，添加跟多的特征项。如果欠拟合是由于特征项不够，没有足够的信息支持模型做判断。
	2）增加模型复杂度。减小正则化系数，使用核函数，集成学习方法。
	3）集成学习方法boosting（能有效解决high bias）


————————————————————————————————————————————————————————————————————————————————————————————————————
【共线性和过拟合】
	共线性：变量之间由于存在高度相关关系而使回归估计不准确。
	共线性会造成冗余，导致过拟合。
	解决方法：排除变量的相关性／加入权重正则。


————————————————————————————————————————————————————————————————————————————————————————————————————
【方差和偏差】
	High bias解决方案：Boosting、复杂模型（非线性模型、增加神经网络中的层）、更多特征
	High Variance解决方案：bagging、简化模型、降维
	此消彼长的关系，所以必须权衡考虑。一般情况下，交叉验证训练可以取得比较好的平衡


————————————————————————————————————————————————————————————————————————————————————————————————————
【ROC，AUC，PR曲线，混淆矩阵】
	-----ROC-----
	横坐标：假阳性率FPR=FP/N，纵坐标：真阳性率TPR=TP/P。(P真实正样本数，N真实负样本数，TP正样本被预测为正，FP负样本被预测为正)
	如何绘制：过不断移动分类器的“截断点”来生成曲线上的点。样本按照预测概率从高到低排序，每一个截断点都会对应一个FPR和TPR。
	直观绘制：1）统计出正负样本的数量P和N接下来，横轴的刻度间隔1/N，纵轴刻度间隔1/P；2）根据预测概率对样本从高到低排序；
		 3）依次遍历样本，从（0,0）开始，正样本：沿纵轴，负样本：沿横轴，直到遍历完所有样本，停在（1,1）
	-----AUC-----
	ROC曲线下的面积大小，能够反映模型性能。
	计算：沿着ROC横轴做积分
	取值：0.5～1
	AUC越大，说明分类器越可能把真正的正样本排在前面，分类性能越好。
	-----PR曲线-----
	横轴：召回率，纵轴：精确率
	绘制：将阈值从高到低移动生成
	-----ROC和PR曲线比较-----
	当正负样本的分布发生变化时，ROC曲线的形状能够基本保持不变，而P-R曲线的形状一般会发生较剧烈的变化。
	ROC适用场景更多，排序、推荐、广告等领域。
	如果希望看到模型在特定数据集上的表现，P-R曲线则能够更直观地反映其性能。
	-----混淆矩阵-----
	ROC曲线绘制的基础，衡量分类型模型准确度中最基本，最直观，计算最简单的方法。
	分别统计分类模型归错类，归对类的观测值个数，然后把结果放在一个表里展示出来。
